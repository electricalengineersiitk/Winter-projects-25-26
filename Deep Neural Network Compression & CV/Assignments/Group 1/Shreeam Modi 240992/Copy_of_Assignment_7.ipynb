{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font size=\"7\"> **Assignment-6**</font>\n",
        "I hope this assignment will give you clarity on how mathematical models like **Multilayer Perceptrons (MLP)** can be made from scratch using **PyTorch** & can be used to solve complex, non-linear geometric problems **without relying on black-box libraries**.\n",
        "\n",
        "---\n",
        "# ⚫ **Mission Critical: The Exclusion Zone Protocol**\n",
        "\n",
        "**Date:** Year 2142  \n",
        "**Location:** Exoplanet *Kepler-186f*   **Clearance:** IITians\n",
        "\n",
        "---\n",
        "\n",
        "### **⚫ The Story**\n",
        "Humanity has colonized the distant exoplanet *Kepler-186f*. While the surface is habitable, the planet's magnetic core is unstable. The **Global Defense Council (GDC)** has identified a dangerous phenomenon known as the **\"Radiation Ring.\"**\n",
        "\n",
        "Sensors indicate that the safe zones on the planet follow a peculiar geometry:\n",
        "* ⚫ **The Core Zone:** Distance $< 2$ km from the colony center (Safe).\n",
        "* ⚫ **The Outer Wilds:** Distance $> 4$ km from the colony center (Safe).\n",
        "* ⚫ **The Dead Zone:** The region **between 2 km and 4 km** is flooded with lethal gamma radiation.\n",
        "\n",
        "Your engineering team has deployed **3,000 sensor drones** across the colony to map this danger. Each drone reports its coordinates $(x, y)$ and a binary label:\n",
        "* `1`: Radiation Detected (Dead Zone)\n",
        "* `0`: Safe Zone\n",
        "\n",
        " **⚫ The Problem:** The sensors are cheap and prone to interference. Approximately **5%** of the drones are malfunctioning and reporting the wrong safety status (noise). The GDC mainframe is a legacy system that forbids the use of modern \"Neural Libraries\" (i.e., you cannot use `torch.nn` or `torch.optim`). You must build a **Multi-Layer Perceptron (MLP) from scratch** to filter out the noise and mathematically define the Exclusion Zone boundaries using **PyTorch**. ( Hint: You know this is a binary classification problem, which Loss function would you use?? )\n",
        "\n",
        "---\n",
        "\n",
        "### **⚫ Your Objective**\n",
        "\n",
        "1.  **Initialize the System:** Use your **Group Number** as the random seed. This ensures your team works on a unique sensor distribution pattern.\n",
        "2.  **Architect the Filter:** Construct a neural network with **3 hidden layers** (16 neurons each) to learn the non-linear \"donut\" shape of the Dead Zone.\n",
        "3.  **Manual Calibration:** You cannot use auto-optimizers. You must manually calculate the gradients (Backpropagation) and update the system weights using **Gradient Descent**.\n",
        "4.  **Verify Integrity:** Split your sensor data (70% training, 30% validation). Prove that your system doesn't just memorize the malfunctioning sensors (overfitting) but actually learns the geometric shape of the Dead Zone.\n",
        "\n",
        "---\n",
        "\n",
        "## ⚫ Engineering Constraints (Read Carefully)\n",
        "\n",
        "**1. Restricted Modules**\n",
        "*  **Forbidden:** You are strictly forbidden from importing `torch.nn` (Layers/Loss) or `torch.optim` (Optimizers).\n",
        "*  **Allowed:** `import torch`, `import matplotlib.pyplot`, `import pandas`, `import numpy`, using `sklearn`.\n",
        "\n",
        "\n",
        "**2. The Mechanics**\n",
        "* **Forward Pass:** Must be implemented using raw matrix multiplication (`torch.matmul`) and bias addition.\n",
        "* **Backward Pass:** You **MAY** use `loss.backward()` to compute gradients automatically (Autograd).\n",
        "* **Optimization:** You **MUST** implement the weight updates manually (Stochastic Gradient Descent).\n",
        "    > `w_new = w_old - learning_rate * w_old.grad`\n",
        "\n",
        "**3. Loss Function**\n",
        "Since `torch.nn` is banned, you must implement **Binary Cross Entropy** manually using basic tensor math.\n",
        "\n",
        "$$Loss = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\cdot \\log(\\hat{y}_i) + (1-y_i) \\cdot \\log(1-\\hat{y}_i)]$$\n",
        "\n",
        "* **Note:** Ensure you handle the log of zero (numerical stability) or use `torch.clamp` to avoid `NaN` errors.\n",
        "\n",
        "**4. Visual Proof:** Your final output must include a Decision Boundary Map showing the \"Donut\" shape.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### ⚫ **The GDC Dashboard (Required Output)**\n",
        "\n",
        "\n",
        "\n",
        "The Global Defense Council requires visual confirmation that your system is stable before we can upload it to the drone fleet. You must generate a **3-Panel Heads-Up Display (HUD)** containing the following telemetry:\n",
        "\n",
        "**1. System Error Trajectory (Loss Plot)**\n",
        "* **Mission:** Plot the **Training Loss** (Blue) vs. **Validation Loss** (Orange) over all epochs.\n",
        "* **Why:** We need to confirm that the system is actually learning and not just diverging (exploding gradients).\n",
        "\n",
        "**2. Integrity Check (Accuracy Plot)**\n",
        "* **Mission:** Plot the **Training Accuracy** vs. **Validation Accuracy**.\n",
        "* **Why:** If Training Accuracy is high (95%) but Validation Accuracy is low (80%), you have failed to generalize. This is a sign of **Overfitting**—memorizing sensor noise instead of the Radiation Ring.\n",
        "\n",
        "**3. Geospatial Threat Map (Decision Boundary)**\n",
        "* **Mission:** Visualize the **Validation Set** on a 2D map.\n",
        "* **Overlay:** Draw the neural network's **Decision Boundary** (the contours where confidence = 0.5).\n",
        "* **Why:** The Commander needs to *see* the \"Donut\" shape. If your boundary looks like a jagged mess, the model is rejected.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "sqmYfcSkoQPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# ===========================================================\n",
        "# PART 1: Data Generation (The Exclusion Zone)\n",
        "# ===========================================================\n",
        "\n",
        "# ⚠️ INSTRUCTION: Replace 1 with your actual Group Number\n",
        "GROUP_NUMBER = 1\n",
        "\n",
        "# Set seed for reproducibility\n",
        "torch.manual_seed(GROUP_NUMBER)\n",
        "np.random.seed(GROUP_NUMBER)\n",
        "\n",
        "def generate_data(n_samples=3000):\n",
        "    \"\"\"\n",
        "    Generates 3000 sensor readings for the Kepler-186f Exclusion Zone.\n",
        "    Shape: Concentric circles (Donut).\n",
        "    Logic:\n",
        "      - Dead Zone (1): 2km < distance < 4km\n",
        "      - Safe Zone (0): distance < 2km OR distance > 4km\n",
        "    \"\"\"\n",
        "    # Generate random coordinates between -5 and 5 km\n",
        "    X = (torch.rand(n_samples, 2) * 10) - 5\n",
        "\n",
        "    # Calculate distance from center (radius)\n",
        "    radius = torch.sqrt(X[:, 0]**2 + X[:, 1]**2)\n",
        "\n",
        "    # Assign Labels: 1 if inside the Dead Zone, 0 otherwise\n",
        "    y = ((radius > 2) & (radius < 4)).float().view(-1, 1)\n",
        "\n",
        "    # Add 5% Noise (Malfunctioning Drones)\n",
        "    n_noise = int(0.05 * n_samples)\n",
        "    noise_indices = torch.randperm(n_samples)[:n_noise]\n",
        "    y[noise_indices] = 1 - y[noise_indices] # Flip labels\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Generate the dataset\n",
        "X_full, y_full = generate_data(3000)\n",
        "\n",
        "print(f\"Data Generated: {X_full.shape} samples.\")\n",
        "print(f\"Target Generated: {y_full.shape} labels.\")"
      ],
      "metadata": {
        "id": "rP6_Oh-3OJ9C",
        "outputId": "c09dff65-7911-4d6a-abd8-609f0663826c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Generated: torch.Size([3000, 2]) samples.\n",
            "Target Generated: torch.Size([3000, 1]) labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_layer(i, o):\n",
        "    w = torch.randn(i, o) * 0.1\n",
        "    b = torch.zeros(1, o)\n",
        "    w.requires_grad_()\n",
        "    b.requires_grad_()\n",
        "    return w, b\n",
        "\n",
        "W1,b1 = init_layer(2,16)\n",
        "W2,b2 = init_layer(16,16)\n",
        "W3,b3 = init_layer(16,16)\n",
        "W4,b4 = init_layer(16,1)\n",
        "\n",
        "def relu(x):\n",
        "    return torch.clamp(x, min=0)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "def forward(x):\n",
        "    x = relu(x @ W1 + b1)\n",
        "    x = relu(x @ W2 + b2)\n",
        "    x = relu(x @ W3 + b3)\n",
        "    return sigmoid(x @ W4 + b4)\n",
        "\n",
        "def bce(yh, y):\n",
        "    eps = 1e-7\n",
        "    yh = torch.clamp(yh, eps, 1 - eps)\n",
        "    return -(y * torch.log(yh) + (1 - y) * torch.log(1 - yh)).mean()\n",
        "\n",
        "lr = 0.05\n",
        "epochs = 400\n",
        "\n",
        "tr_l, va_l, tr_a, va_a = [], [], [], []\n",
        "\n",
        "for e in range(epochs):\n",
        "    yh = forward(Xtr)\n",
        "    loss = bce(yh, ytr)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for p in [W1,b1,W2,b2,W3,b3,W4,b4]:\n",
        "            p -= lr * p.grad\n",
        "            p.grad.zero_()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tr_l.append(loss.item())\n",
        "        tr_a.append(((yh > 0.5) == ytr).float().mean().item())\n",
        "        yv = forward(Xva)\n",
        "        va_l.append(bce(yv, yva).item())\n",
        "        va_a.append(((yv > 0.5) == yva).float().mean().item())\n",
        "\n",
        "    if (e + 1) % 50 == 0:\n",
        "        print(f\"Epoch {e+1} | Train Loss {tr_l[-1]:.4f} | Val Loss {va_l[-1]:.4f}\")\n",
        "\n",
        "print(\"Training complete\")\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "ax[0].plot(tr_l, label=\"Train\")\n",
        "ax[0].plot(va_l, label=\"Val\")\n",
        "ax[0].set_title(\"Loss\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(tr_a, label=\"Train\")\n",
        "ax[1].plot(va_a, label=\"Val\")\n",
        "ax[1].set_title(\"Accuracy\")\n",
        "ax[1].legend()\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-5, 5, 300), np.linspace(-5, 5, 300))\n",
        "grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    zz = forward(grid).view(xx.shape)\n",
        "\n",
        "ax[2].contourf(xx, yy, zz, levels=50, cmap=\"coolwarm\", alpha=0.6)\n",
        "ax[2].contour(xx, yy, zz, levels=[0.5], colors=\"black\")\n",
        "ax[2].scatter(Xva[:, 0], Xva[:, 1], c=yva[:, 0], s=5, cmap=\"coolwarm\")\n",
        "ax[2].set_title(\"Decision Boundary\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Final Train Acc:\", tr_a[-1])\n",
        "print(\"Final Val Acc:\", va_a[-1])"
      ],
      "metadata": {
        "id": "Ng1YWGuJZvgg",
        "outputId": "11afd8ed-dab3-4533-aaef-58aef617c99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Xtr' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-626510185.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0myh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Xtr' is not defined"
          ]
        }
      ]
    }
  ]
}
