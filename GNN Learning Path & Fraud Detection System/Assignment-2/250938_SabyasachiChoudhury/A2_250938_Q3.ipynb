{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDS-bIcGDIzu",
        "outputId": "6e8e858e-daae-4105-9e3d-5c8be289529d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.2832\n",
            "Epoch 1000, Loss: 0.2452\n",
            "Epoch 2000, Loss: 0.2124\n",
            "Epoch 3000, Loss: 0.1503\n",
            "Epoch 4000, Loss: 0.0572\n",
            "Epoch 5000, Loss: 0.0209\n",
            "Epoch 6000, Loss: 0.0107\n",
            "Epoch 7000, Loss: 0.0067\n",
            "Epoch 8000, Loss: 0.0047\n",
            "Epoch 9000, Loss: 0.0035\n",
            "[[ 5.22722431  0.98707488  0.68186502  6.01151874]\n",
            " [-3.16613113 -3.99951104  2.91152228  5.80878724]]\n",
            "[[-6.57254498]\n",
            " [ 4.63984181]\n",
            " [-3.9456002 ]\n",
            " [ 8.04506769]]\n",
            "[[ 1.24785544  0.50324162 -2.14896976 -2.053226  ]]\n",
            "[[-1.53894177]]\n",
            "\n",
            "Final predictions:\n",
            "[[0.0372988 ]\n",
            " [0.94914558]\n",
            " [0.94481534]\n",
            " [0.06424562]]\n",
            "\n",
            "Binary output:\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Architecture: 2 input neurons, 4 hidden neurons, 1 output neurons, MSE loss, sigmoid activations at each layer.\n",
        "\n",
        "Example of found solution weights\n",
        "\n",
        "W1: [[ 5.22722431  0.98707488  0.68186502  6.01151874]\n",
        " [-3.16613113 -3.99951104  2.91152228  5.80878724]]\n",
        "\n",
        "W2: [[-6.57254498]\n",
        " [ 4.63984181]\n",
        " [-3.9456002 ]\n",
        " [ 8.04506769]]\n",
        "\n",
        "B1: [[ 1.24785544  0.50324162 -2.14896976 -2.053226  ]]\n",
        "\n",
        "B2: [[-1.53894177]]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "y = np.array([[0], [1], [1], [0]])  # XOR labels\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(a):\n",
        "    # assumes 'a' is already sigmoid(z)\n",
        "    return a * (1 - a)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Initialize weights and biases\n",
        "W1 = np.random.randn(2, 4)   # input â†’ hidden\n",
        "b1 = np.zeros((1, 4))\n",
        "\n",
        "W2 = np.random.randn(4, 1)   # hidden â†’ output\n",
        "b2 = np.zeros((1, 1))\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    z1 = X @ W1 + b1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = a1 @ W2 + b2\n",
        "    y_hat = sigmoid(z2)\n",
        "\n",
        "    loss = np.mean((y - y_hat) ** 2)\n",
        "\n",
        "    dL_dyhat = y_hat - y\n",
        "    dL_dz2 = dL_dyhat * sigmoid_derivative(y_hat)\n",
        "\n",
        "    dW2 = a1.T @ dL_dz2\n",
        "    db2 = np.sum(dL_dz2, axis=0, keepdims=True)\n",
        "\n",
        "    dL_da1 = dL_dz2 @ W2.T\n",
        "    dL_dz1 = dL_da1 * sigmoid_derivative(a1)\n",
        "\n",
        "    dW1 = X.T @ dL_dz1\n",
        "    db1 = np.sum(dL_dz1, axis=0, keepdims=True)\n",
        "\n",
        "    W2 -= learning_rate * dW2\n",
        "    b2 -= learning_rate * db2\n",
        "    W1 -= learning_rate * dW1\n",
        "    b1 -= learning_rate * db1\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "\n",
        "print(W1)\n",
        "print(W2)\n",
        "print(b1)\n",
        "print(b2)\n",
        "\n",
        "print(\"\\nFinal predictions:\")\n",
        "predictions = sigmoid(sigmoid(X @ W1 + b1) @ W2 + b2)\n",
        "print(predictions)\n",
        "\n",
        "print(\"\\nBinary output:\")\n",
        "print((predictions > 0.5).astype(int))"
      ]
    }
  ]
}