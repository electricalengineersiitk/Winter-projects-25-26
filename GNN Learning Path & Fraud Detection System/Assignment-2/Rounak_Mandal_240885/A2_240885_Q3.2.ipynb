{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0E3Y2QMTie52wBU03aDCc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkUxnd5QcxG5","executionInfo":{"status":"ok","timestamp":1765810122200,"user_tz":-330,"elapsed":502,"user":{"displayName":"Rounak Mandal","userId":"05460598004105435528"}},"outputId":"0dbad5ec-d699-4b3d-d979-0bd62fa32eec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Final Predicted Outputs (after training):\n","[[0.07361764]\n"," [0.93011137]\n"," [0.9296496 ]\n"," [0.07747827]]\n","\n","Rounded Outputs:\n","[[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n"]}],"source":["import numpy as np\n","\n","# Define the XOR Data\n","# Inputs: (4 samples, 2 features)\n","X = np.array([[0, 0],\n","              [0, 1],\n","              [1, 0],\n","              [1, 1]])\n","\n","# Targets: (4 samples, 1 output)\n","y = np.array([[0],\n","              [1],\n","              [1],\n","              [0]])\n","\n","# Define Activation Function (Sigmoid) and its Derivative\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Initialize Parameters\n","# Architecture: 2 Input -> 2 Hidden -> 1 Output\n","input_neurons = 2\n","hidden_neurons = 2\n","output_neurons = 1\n","learning_rate = 0.1\n","epochs = 10000\n","\n","# Initialize weights and biases randomly\n","# Weights between Input and Hidden Layer\n","weights_input_hidden = np.random.uniform(size=(input_neurons, hidden_neurons))\n","bias_hidden = np.random.uniform(size=(1, hidden_neurons))\n","\n","# Weights between Hidden and Output Layer\n","weights_hidden_output = np.random.uniform(size=(hidden_neurons, output_neurons))\n","bias_output = np.random.uniform(size=(1, output_neurons))\n","\n","# Training Loop\n","for i in range(epochs):\n","    # Forward Propagation\n","    # Calculate hidden layer input and output\n","    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n","    hidden_layer_output = sigmoid(hidden_layer_input)\n","\n","    # Calculate output layer input and output\n","    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n","    predicted_output = sigmoid(output_layer_input)\n","\n","    # Backpropagation\n","    # Calculate Error\n","    error = y - predicted_output\n","\n","    # Calculate gradients for Output Layer\n","    d_predicted_output = error * sigmoid_derivative(predicted_output)\n","\n","    # Calculate Error contribution from Hidden Layer\n","    error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T)\n","\n","    # Calculate gradients for Hidden Layer\n","    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n","\n","    # Update Weights and Biases\n","    weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n","    bias_output += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n","\n","    weights_input_hidden += X.T.dot(d_hidden_layer) * learning_rate\n","    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n","\n","# Testing and Output\n","print(\"Final Predicted Outputs (after training):\")\n","print(predicted_output)\n","print(\"\\nRounded Outputs:\")\n","print(np.round(predicted_output))"]}]}