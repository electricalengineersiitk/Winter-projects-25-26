{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LjU9GoJabTRX"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "\n",
        "y = np.array([[0], [1], [1], [0]])"
      ],
      "metadata": {
        "id": "ksmXEd6ybvBU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(z):\n",
        "    return z * (1 - z)"
      ],
      "metadata": {
        "id": "5qLdj0aBbwO6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb4801ee"
      },
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "W1 = np.random.randn(2, 4)\n",
        "b1 = np.zeros((1, 4))\n",
        "\n",
        "W2 = np.random.randn(4, 1)\n",
        "b2 = np.zeros((1, 1))\n",
        "lr = 0.5\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e752ea08",
        "outputId": "674965c1-6385-47d5-8922-fc3050672f27"
      },
      "source": [
        "for epoch in range(20000):\n",
        "\n",
        "\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    y_hat = sigmoid(z2)\n",
        "\n",
        "\n",
        "    loss = np.mean((y - y_hat) ** 2)\n",
        "\n",
        "\n",
        "    d_y_hat = (y_hat - y) * sigmoid_derivative(y_hat)\n",
        "\n",
        "    dW2 = np.dot(a1.T, d_y_hat)\n",
        "    db2 = np.sum(d_y_hat, axis=0, keepdims=True)\n",
        "\n",
        "    d_hidden = np.dot(d_y_hat, W2.T) * sigmoid_derivative(a1)\n",
        "\n",
        "    dW1 = np.dot(X.T, d_hidden)\n",
        "    db1 = np.sum(d_hidden, axis=0, keepdims=True)\n",
        "\n",
        "\n",
        "    W2 -= lr * dW2\n",
        "    b2 -= lr * db2\n",
        "    W1 -= lr * dW1\n",
        "    b1 -= lr * db1\n",
        "    if epoch % 2000 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss:.6f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.283190\n",
            "Epoch 2000, Loss: 0.002784\n",
            "Epoch 4000, Loss: 0.000773\n",
            "Epoch 6000, Loss: 0.000415\n",
            "Epoch 8000, Loss: 0.000276\n",
            "Epoch 10000, Loss: 0.000204\n",
            "Epoch 12000, Loss: 0.000160\n",
            "Epoch 14000, Loss: 0.000132\n",
            "Epoch 16000, Loss: 0.000111\n",
            "Epoch 18000, Loss: 0.000096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "940efccf",
        "outputId": "82983ee8-6e9c-42c5-8d64-15a47bb518e9"
      },
      "source": [
        "print(f\"Final Predictions (y_hat):\\n{y_hat}\")\n",
        "print(f\"Final Loss : {loss:.6f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Predictions (y_hat):\n",
            "[[0.00644882]\n",
            " [0.99180267]\n",
            " [0.98983549]\n",
            " [0.01117524]]\n",
            "Final Loss : 0.000084\n"
          ]
        }
      ]
    }
  ]
}