{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Command & Control for UAV's\n",
        "\n",
        "## Assignment 2 soln"
      ],
      "metadata": {
        "id": "PHFCMGbyswMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1: Theoretical Questions**"
      ],
      "metadata": {
        "id": "QauRlg4lriwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Computational Graphs & Gradients"
      ],
      "metadata": {
        "id": "PWDwT0-UrqiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, gradient accumulation happens by default. When we call loss.backward(), the gradients computed during backpropagation are added to the values already stored in the .grad attribute of the leaf tensors, rather than replacing them. In other words, PyTorch treats the gradient buffers as running sums unless we manually clear them.\n",
        "Because of this behavior, a typical training loop includes a call to optimizer.zero_grad() before computing the next backward pass. This step resets all stored gradients to zero so that each optimization step is based only on the gradients from the current batch.\n",
        "If we forget to call zero_grad(), the gradients from previous iterations will continue accumulating across steps. Mathematically, this means the parameter update will use the sum of gradients from multiple batches, which alters the effective learning rate, distorts the optimization dynamics, and can lead to unstable or incorrect training behavior. While intentional accumulation can be useful in techniques like gradient accumulation for small batch training, it must be controlled explicitly.\n"
      ],
      "metadata": {
        "id": "umLWq_zYrdkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Tensors: View vs. Reshape"
      ],
      "metadata": {
        "id": "TA0STTg9sWqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, both .view() and .reshape() are used to change the shape of a tensor, but they behave differently with respect to memory layout. The .view() method can only be applied when the underlying tensor is stored in a single, contiguous block of memory. If the tensor has been transposed, sliced, or modified in a way that makes it non-contiguous, calling .view() will fail because it cannot simply reinterpret the existing memory as a new shape.\n",
        "\n",
        "The .reshape() method, however, is more flexible. It first tries to return a view of the tensor (just like .view()), but if the tensor is non-contiguous, it will automatically create a new contiguous copy in memory and then reshape it. This allows the operation to succeed even when the original tensor layout is fragmented.\n",
        "\n",
        "Because of this behavior, .reshape() is generally considered safer when you are unsure about the tensorâ€™s memory layout or strides. However, when you know for sure that a tensor is already contiguous and you want to avoid any chance of copying data, .view() can be more efficient."
      ],
      "metadata": {
        "id": "MdKCMHnvrvGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Device Management (CPU vs. GPU)\n"
      ],
      "metadata": {
        "id": "Qiz8LVnLsTgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, every tensor is associated with a specific device, such as the CPU or GPU. Operations like addition or multiplication can only be performed when all participating tensors are on the same device. If we try to combine a tensor on the CPU with another tensor on the GPU, PyTorch raises a device mismatch error, because it does not implicitly move data across devices. To fix this, we must manually transfer one of the tensors so that both exist on either the CPU or the GPU.\n",
        "\n",
        "When we move a model to the GPU using model.to('cuda'), all of its parameters and buffers are transferred to GPU memory. However, tensors that are newly created inside the forward method are not automatically placed on the GPU. By default, they are created on the CPU unless we explicitly specify the device. If such tensors interact with the model parameters on the GPU, it will again result in a device mismatch error. Therefore, any intermediate tensors inside the model must also be created on the same device as the model to ensure smooth execution."
      ],
      "metadata": {
        "id": "lbHlQIGlsUkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2: Programming Challenges**"
      ],
      "metadata": {
        "id": "cCFMfrYTd-kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Tensor Manipulation (The Image Mask)"
      ],
      "metadata": {
        "id": "DVc_ggamhflw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HXbjiwyjZHCb",
        "outputId": "fadb804d-0446-452e-f8a5-c88f5a3d045f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 1.,  ..., 0., 1., 1.],\n",
            "         [1., 1., 0.,  ..., 1., 0., 0.],\n",
            "         [0., 0., 1.,  ..., 1., 1., 0.],\n",
            "         ...,\n",
            "         [0., 0., 1.,  ..., 0., 1., 0.],\n",
            "         [1., 1., 1.,  ..., 1., 0., 1.],\n",
            "         [0., 0., 1.,  ..., 1., 1., 0.]],\n",
            "\n",
            "        [[1., 0., 1.,  ..., 1., 0., 1.],\n",
            "         [0., 0., 1.,  ..., 1., 0., 1.],\n",
            "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [1., 1., 1.,  ..., 0., 1., 1.],\n",
            "         [1., 1., 0.,  ..., 1., 0., 0.],\n",
            "         [1., 1., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0.,  ..., 1., 1., 1.],\n",
            "         [0., 0., 0.,  ..., 1., 0., 1.],\n",
            "         [1., 1., 0.,  ..., 0., 0., 1.],\n",
            "         ...,\n",
            "         [0., 1., 1.,  ..., 0., 1., 0.],\n",
            "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 1.]],\n",
            "\n",
            "        [[1., 0., 1.,  ..., 1., 0., 1.],\n",
            "         [1., 0., 1.,  ..., 0., 1., 1.],\n",
            "         [1., 0., 0.,  ..., 1., 1., 1.],\n",
            "         ...,\n",
            "         [0., 0., 1.,  ..., 1., 1., 0.],\n",
            "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 1.,  ..., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def process_images(images):\n",
        "    return torch.where(images >= 0.5,0.0,1.0)\n",
        "images = torch.rand(4, 28, 28)\n",
        "output = process_images(images)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. The \"Safe\" Autograd (Gradient Checking)"
      ],
      "metadata": {
        "id": "Ro9utu4yhKzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.tensor(4.0, requires_grad=True)\n",
        "y = x**3 + 2*x\n",
        "y.backward()\n",
        "print(\"Gradient:\", x.grad)\n",
        "manual_cal = 3*(4**2) + 2\n",
        "\n",
        "# sanity check\n",
        "if x.grad.item() != manual_cal:\n",
        "    raise ValueError(\"gradient does not match manual calculation\")\n",
        "\n",
        "print( manual_cal)\n",
        "\n"
      ],
      "metadata": {
        "id": "NL_Wi4dqhMNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3: Advanced OOP Challenges**"
      ],
      "metadata": {
        "id": "iJu-G5QjiXdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Class Interaction (Custom Datasets)"
      ],
      "metadata": {
        "id": "l16Z234ToX8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Numdataset(Dataset):\n",
        "    def __init__(self, numbers):\n",
        "        self.numbers = numbers\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.numbers)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        num = self.numbers[index]\n",
        "        x = torch.tensor(float(num))\n",
        "        y = torch.tensor(float(num * 2))\n",
        "        return x, y\n",
        "\n",
        "data = Numdataset([1, 2, 3, 4])\n",
        "\n",
        "print(\"length \", len(data))\n",
        "print(\"item0 \", data[0])\n",
        "print(\"item2 \", data[2])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDZ9noXJmUZ8",
        "outputId": "f4085869-9f34-4498-b5ce-39defc8a30f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length: 4\n",
            "item 0: (tensor(1.), tensor(2.))\n",
            "item 2: (tensor(3.), tensor(6.))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Model Encapsulation (nn.Module)"
      ],
      "metadata": {
        "id": "9mKFs4JWohIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(10, 5)\n",
        "        self.fc2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "model = SimpleClassifier()\n",
        "dummy_input = torch.rand(2, 10)\n",
        "output = model(dummy_input)\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "tEblt8Fvoksf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. The Training Loop (Logic Integration)\n"
      ],
      "metadata": {
        "id": "wF1ucGR2qNFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model, inputs, targets, optimizer, criterion):\n",
        "    # Forward pass\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    # Loss calculation\n",
        "    loss = criterion(predictions, targets)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Return scalar loss value\n",
        "    return loss.item()\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Create model\n",
        "model = SimpleClassifier()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Dummy inputs and targets\n",
        "inputs = torch.rand(4, 10)\n",
        "targets = torch.rand(4, 1)\n",
        "\n",
        "# Run one training step\n",
        "loss = train_step(model, inputs, targets, optimizer, criterion)\n",
        "\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "id": "YWpr4TaeqRYv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}