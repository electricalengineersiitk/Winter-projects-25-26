{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "25207d05",
      "metadata": {
        "id": "25207d05"
      },
      "source": [
        "# Assignment: Training EEGNet on P300 EEG Data\n",
        "\n",
        "In this assignment, you will work with real EEG data from a P300 speller experiment and implement the EEGNet architecture to detect P300 responses. The emphasis of this assignment is on understanding and implementing the EEGNet model rather than extensive signal preprocessing.\n",
        "\n",
        "**Instructions:**\n",
        "- Complete the provided code scaffolding\n",
        "- Fill in missing logic where indicated\n",
        "- Focus especially on the EEGNet architecture and training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cebbfa87",
      "metadata": {
        "id": "cebbfa87"
      },
      "source": [
        "## Part 1: Loading and Inspecting the Dataset\n",
        "\n",
        "In this section, you will load the EEG dataset and inspect its basic structure. The dataset contains continuous EEG recordings along with stimulus and label information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5e1539f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5e1539f",
        "outputId": "7b68da61-ddf3-48ad-81f2-86d857831fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "dict_keys(['__header__', '__version__', '__globals__', 'Signal', 'TargetChar', 'Flashing', 'StimulusCode', 'StimulusType'])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "# TODO: Update the path if needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = sio.loadmat('/content/drive/MyDrive/Subject_A_Train.mat')\n",
        "\n",
        "# Inspect available keys\n",
        "print(data.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb60b42b",
      "metadata": {
        "id": "fb60b42b"
      },
      "source": [
        "## Part 2: Understanding the Experimental Design\n",
        "\n",
        "The P300 speller paradigm is based on detecting brain responses to rare target stimuli. In this section, you will identify how stimulus timing and labels are encoded in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6277e4ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6277e4ec",
        "outputId": "bed1dc4f-1f7e-4ca5-86f4-89916f2d577e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(85, 7794, 64)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Identify which variables correspond to\n",
        "# 1. Continuous EEG signal\n",
        "# 2. Stimulus onset information\n",
        "# 3. Target vs non-target labels\n",
        "# Hint: Look for variables related to stimulus codes and stimulus types\n",
        "TargetChar=data['TargetChar']\n",
        "TargetChar=np.array(list(TargetChar[0]))\n",
        "signal = data['Signal']# shape is (trials,samples,channels); one trial corresponds to flashing of one particular letter\n",
        "flashing = data['Flashing']\n",
        "stimulus_code = data['StimulusCode']\n",
        "stimulus_type = data.get('StimulusType')\n",
        "\n",
        "n_chars=signal.shape[0]\n",
        "labels_list = []\n",
        "\n",
        "for char_idx in range(n_chars):\n",
        "  char_type = stimulus_type[char_idx]\n",
        "  char_flashing = flashing[char_idx]\n",
        "  stimulus_onsets = np.where(np.diff(char_flashing) == 1)[0] + 1\n",
        "  for onset in stimulus_onsets:\n",
        "     label = char_type[onset]\n",
        "     labels_list.append(label)\n",
        "  labels = np.array(labels_list)\n",
        "print(signal.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b2e84b",
      "metadata": {
        "id": "f0b2e84b"
      },
      "source": [
        "## Part 3: EEG Epoch Extraction\n",
        "\n",
        "EEGNet does not operate on continuous EEG. Instead, the signal must be segmented into short epochs following each stimulus. This step converts raw EEG into trials suitable for supervised learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a5a4241",
      "metadata": {
        "id": "8a5a4241"
      },
      "outputs": [],
      "source": [
        "def extract_epochs(signal, stimulus_onsets, labels, fs, t_start=0.0, t_end=0.8):\n",
        "    \"\"\"\n",
        "    Extract EEG epochs around each stimulus onset.\n",
        "\n",
        "    Parameters:\n",
        "    - signal: continuous EEG array of shape (trials,time, channels)\n",
        "    - stimulus_onsets: indices where stimuli occur\n",
        "    - labels: target/non-target labels per stimulus\n",
        "    - fs: sampling frequency in Hz\n",
        "    - t_start: start time (seconds) relative to stimulus\n",
        "    - t_end: end time (seconds) relative to stimulus\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    - epochs: array of shape (num_trials, channels, time)\n",
        "    - y: corresponding labels\n",
        "    \"\"\"\n",
        "    # TODO: Implement epoch extraction logic\n",
        "    # Hint: Convert time window to samples using fs\n",
        "    n_chars = signal.shape[0]\n",
        "    epoch_samples = int((t_end-t_start) * fs) #converts time to no. of samples to extract\n",
        "    epochs_list=[]\n",
        "    for char_idx in range(n_chars):\n",
        "        char_signal = signal[char_idx]\n",
        "        for onset in stimulus_onsets:\n",
        "          if onset+epoch_samples<=len(char_signal):\n",
        "            epoch=char_signal[onset:onset+epoch_samples,]\n",
        "            epochs_list.append(epoch)\n",
        "    epochs = np.array(epochs_list) #epochs has shape (trials,samples, channels)\n",
        "    epochs=np.transpose(epochs,axes=(0,2,1))#now shape is (trials,channels,samples)\n",
        "    return epochs,labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24965719",
      "metadata": {
        "id": "24965719"
      },
      "source": [
        "## Part 4: Preparing Data for EEGNet\n",
        "\n",
        "In this section, you will perform minimal preprocessing to make the data compatible with EEGNet. Extensive signal processing is not required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1f011a",
      "metadata": {
        "id": "cc1f011a"
      },
      "outputs": [],
      "source": [
        "def prepare_for_eegnet(epochs):\n",
        "    \"\"\"\n",
        "    Prepare EEG epochs for input into EEGNet.\n",
        "\n",
        "    Expected input shape: (trials, channels, time)\n",
        "    Expected output shape: (trials, 1, channels, time)\n",
        "    \"\"\"\n",
        "    # TODO: Add singleton dimension required by Conv2D\n",
        "    # Hint: Use numpy.expand_dims\n",
        "    epochs=np.expand_dims(epochs,axis=1)\n",
        "    print(epochs.shape)\n",
        "    return epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c11d7e4a",
      "metadata": {
        "id": "c11d7e4a"
      },
      "source": [
        "## Part 5: Implementing EEGNet\n",
        "\n",
        "This is the core part of the assignment. You will implement the EEGNet architecture as discussed in class. Focus on matching the block structure and understanding the role of each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111b385d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "111b385d",
        "outputId": "6c710389-9cd2-46bf-a84b-574e0e3c904b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ separable_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">194</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m204\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m204\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │           \u001b[38;5;34m816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m204\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │            \u001b[38;5;34m32\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m204\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m204\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m204\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ separable_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m194\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,706</span> (10.57 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,706\u001b[0m (10.57 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,626</span> (10.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,626\u001b[0m (10.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> (320.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m80\u001b[0m (320.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv2D, DepthwiseConv2D,\n",
        "                                     SeparableConv2D, BatchNormalization,Activation,\n",
        "                                     AveragePooling2D, Dropout, Flatten, Dense)\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "\n",
        "def EEGNet(nb_classes, Chans, Timepts, F1=8, D=2, F2=16, dropoutRate=0.5):\n",
        "    \"\"\"\n",
        "    EEGNet architecture.\n",
        "\n",
        "    Parameters:\n",
        "    - nb_classes: number of output classes\n",
        "    - Chans: number of EEG channels\n",
        "    - Samples: number of time samples per epoch\n",
        "    - F1: number of temporal filters\n",
        "    - D: depth multiplier for spatial filters\n",
        "    - F2: number of pointwise filters\n",
        "    \"\"\"\n",
        "\n",
        "    input1 = Input(shape=( Chans, Timepts,1))\n",
        "    kernLength=Timepts//2\n",
        "    # Block 1: Temporal Convolution\n",
        "    block1 = Conv2D(F1, (1, kernLength), padding = 'same',use_bias = False)(input1)\n",
        "    block1 = BatchNormalization()(block1)\n",
        "    # Block 1: Spatial Convolution\n",
        "    block1 = DepthwiseConv2D((Chans, 1), use_bias = False,depth_multiplier = D,depthwise_constraint = max_norm(1.))(block1)\n",
        "    block1 = BatchNormalization()(block1)\n",
        "    block1 = Activation('elu')(block1)\n",
        "    block1 = AveragePooling2D((1, 4))(block1)\n",
        "    block1 = Dropout(dropoutRate)(block1)\n",
        "\n",
        "    # Block 2: Separable Convolution\n",
        "    block2 = SeparableConv2D(F2, (1, 16),use_bias = False, padding = 'same')(block1)\n",
        "    block2 = BatchNormalization()(block2)\n",
        "    block2 = Activation('elu')(block2)\n",
        "    block2 = AveragePooling2D((1, 8))(block2)\n",
        "    block2 = Dropout(dropoutRate)(block2)\n",
        "\n",
        "    # Classification\n",
        "    flatten = Flatten(name = 'flatten')(block2)\n",
        "    dense = Dense(nb_classes, name = 'dense',kernel_constraint = max_norm(.25))(flatten)\n",
        "    softmax = Activation('softmax', name = 'softmax')(dense)\n",
        "\n",
        "    return Model(inputs=input1, outputs=softmax)\n",
        "# TODO: Instantiate the EEGNet model and print the summary\n",
        "model=EEGNet(2,64,204,8,2,16,.5)\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b44b13",
      "metadata": {
        "id": "c3b44b13"
      },
      "source": [
        "## Part 6: Training the Model\n",
        "\n",
        "In this section, you will train EEGNet to distinguish between P300 and non-P300 EEG epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35a669b2",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "35a669b2",
        "outputId": "ec192476-6f7d-4a27-cd02-40f03e14de82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15215, 1, 64, 204)\n",
            "Epoch 1/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 245ms/step - accuracy: 0.8346 - loss: 0.4028 - val_accuracy: 0.8400 - val_loss: 0.3999\n",
            "Epoch 2/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 236ms/step - accuracy: 0.8364 - loss: 0.4028 - val_accuracy: 0.8357 - val_loss: 0.3952\n",
            "Epoch 3/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 241ms/step - accuracy: 0.8369 - loss: 0.4037 - val_accuracy: 0.8390 - val_loss: 0.3917\n",
            "Epoch 4/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 234ms/step - accuracy: 0.8414 - loss: 0.3860 - val_accuracy: 0.8363 - val_loss: 0.3917\n",
            "Epoch 5/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 241ms/step - accuracy: 0.8462 - loss: 0.3751 - val_accuracy: 0.8409 - val_loss: 0.3916\n",
            "Epoch 6/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 243ms/step - accuracy: 0.8433 - loss: 0.3762 - val_accuracy: 0.8363 - val_loss: 0.3884\n",
            "Epoch 7/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 234ms/step - accuracy: 0.8390 - loss: 0.3838 - val_accuracy: 0.8357 - val_loss: 0.3917\n",
            "Epoch 8/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 235ms/step - accuracy: 0.8459 - loss: 0.3773 - val_accuracy: 0.8396 - val_loss: 0.3870\n",
            "Epoch 9/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 234ms/step - accuracy: 0.8398 - loss: 0.3821 - val_accuracy: 0.8400 - val_loss: 0.3860\n",
            "Epoch 10/10\n",
            "\u001b[1m1522/1522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 244ms/step - accuracy: 0.8402 - loss: 0.3809 - val_accuracy: 0.8367 - val_loss: 0.3833\n"
          ]
        }
      ],
      "source": [
        "# TODO: Split the dataset into training and validation sets\n",
        "epochs,labels=extract_epochs(signal, stimulus_onsets, labels, fs=256, t_start=0.0, t_end=0.8)\n",
        "epochs=prepare_for_eegnet(epochs)\n",
        "epochs=np.transpose(epochs,axes=(0,2,3,1))\n",
        "x_train,x_val,y_train,y_val=train_test_split(epochs,labels,test_size=.2,random_state=42,stratify=labels)\n",
        "y_train=to_categorical(y_train,2)\n",
        "y_val=to_categorical(y_val,2)\n",
        "# TODO: Compile the model with an appropriate loss and optimizer\n",
        "# Hint: Use categorical cross-entropy and Adam optimizer\n",
        "model.compile(optimizer='adam',  # Default lr=0.001 works well\n",
        "    loss='categorical_crossentropy',  # Multi-class classification\n",
        "    metrics=['accuracy'])\n",
        "# TODO: Train the model and store the training history\n",
        "#conert epochs to samples,channels timepoints,1\n",
        "history=model.fit(x_train,y_train,batch_size=8,epochs=10,validation_data=(x_val,y_val),verbose=1)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}