{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "x422GyParjWf"
   },
   "outputs": [],
   "source": [
    "# importing all the required libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8vrqGt_frm0p"
   },
   "outputs": [],
   "source": [
    "# preprocessing the image to feed it to the vit_model\n\n@dataclass\nclass SiglipVisionConfig:\n    num_hidden_layers: int = 6\n    num_channels: int = 3       # channels in input image - 3 - RGB\n    image_size: int = 32        # CIFAR10 dataset images are 32x32\n    patch_size: int = 4         # 4x4 patches for 32x32 -> 64 patches\n    num_attention_heads: int = 8# number of attention heads\n    hidden_size: int = 384\n    intermediate_size: int = 1536\n    num_classes: int = 10       # since CIFAR10 has 10 classes\n    layer_norm_eps: float = 1e-6\n    attention_dropout: float = 0.1\n    dropout: float = 0.1\n\n# imager preprocessing for CIFAR10\ndef get_cifar10_transforms():\n\n    train_transform = transforms.Compose([\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomCrop(32, padding=4),\n        transforms.ToTensor(),               # converts the images to a tensor\n        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])  # normalizes the image tensor\n    ])\n\n    test_transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.247, 0.243, 0.261])\n    ])\n    return train_transform, test_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LI98IRBgrpNR"
   },
   "outputs": [],
   "source": [
    "# defining the EMBEDDINGS LAYER CLASS\n",
    "\n",
    "class SiglipVisionEmbeddings(nn.Module):\n",
    "    def __init__(self, config: SiglipVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        # basic parameters -\n",
    "        self.num_channels = config.num_channels\n",
    "        self.embed_dim = config.hidden_size # each image patch is going to be turned into a vector of 384 dimensions\n",
    "        self.image_size = config.image_size # image size is 32x32 pixels\n",
    "        self.patch_size = config.patch_size # each patch has a size of 4x4 pixels\n",
    "\n",
    "        # convolution used to create patch embeddings\n",
    "        self.patch_embedding = nn.Conv2d(\n",
    "            in_channels=self.num_channels,\n",
    "            out_channels=self.embed_dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size,\n",
    "            padding='valid'\n",
    "        )\n",
    "\n",
    "        # calculating the number of patches were going to get-\n",
    "        self.num_patches = (self.image_size // self.patch_size) ** 2  # 32/4 = 8x8 = 64 patches\n",
    "        self.num_positions = self.num_patches + 1                     # +1 for CLS token\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, self.embed_dim))\n",
    "        # creating the positional embedding layer -> creates a lookup table of size num_patches x embed_dim\n",
    "        self.position_embedding = nn.Embedding(self.num_positions, self.embed_dim)\n",
    "\n",
    "        self.register_buffer(\n",
    "            # storing position indices -\n",
    "            \"position_ids\",\n",
    "            torch.arange(self.num_positions).expand(1, -1),\n",
    "            persistent=False\n",
    "        )\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor:\n",
    "        # getting batch size and image dimensions -\n",
    "        B, C, H, W = pixel_values.shape # assigning the pixel values to Batch, Channel, Height and Width\n",
    "\n",
    "        patch_embeds = self.patch_embedding(pixel_values)\n",
    "        # flattening and reshaping patches\n",
    "        embeddings = patch_embeds.flatten(2).transpose(1, 2)  # B, num_patches, embed_dim\n",
    "\n",
    "        # adding CLS token\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        embeddings = torch.cat((cls_tokens, embeddings), dim=1)\n",
    "\n",
    "        # adding the position embeddings to patch embeddings\n",
    "        embeddings = embeddings + self.position_embedding(self.position_ids)\n",
    "        return self.dropout(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jfYKzrizrrZS"
   },
   "outputs": [],
   "source": [
    "# MLP LAYER\n",
    "\n",
    "class SiglipMLP(nn.Module):\n",
    "    def __init__(self, config: SiglipVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # fully connected layer 1\n",
    "        self.fc1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        # fully connected layer 2\n",
    "        self.fc2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        # using dropout for regularization -\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.fc1(hidden_states)\n",
    "        # applying the non linearity activation function -\n",
    "        hidden_states = F.gelu(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.fc2(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nLgkVbiirtt0"
   },
   "outputs": [],
   "source": [
    "# ATTENTION LAYER (part of Encoder Layer)\n",
    "\n",
    "class SiglipAttention(nn.Module):\n",
    "    def __init__(self, config: SiglipVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.num_heads = config.num_attention_heads\n",
    "        self.head_dim = self.embed_dim // self.num_heads # dimensions per head\n",
    "        self.dropout = config.attention_dropout\n",
    "\n",
    "        # initialising three linear transformations for key, query and value\n",
    "        self.q_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "        self.k_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "        self.v_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)\n",
    "\n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=True)  # this gives the output projection\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        B, T, C = hidden_states.shape # B = batch, T = tokens, C = channels\n",
    "\n",
    "        q_states = self.q_proj(hidden_states).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2)\n",
    "        k_states = self.k_proj(hidden_states).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2)\n",
    "        v_states = self.v_proj(hidden_states).view(B, T, self.num_heads, C // self.num_heads).transpose(1, 2)\n",
    "\n",
    "        # scaled dot product attention -\n",
    "        attn_weights = (q_states @ k_states.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "\n",
    "        attn_weights = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        # multiply attention with values -\n",
    "        attn_outs = attn_weights @ v_states\n",
    "\n",
    "        attn_outs = attn_outs.transpose(1, 2).reshape(B, T, C)\n",
    "        return self.out_proj(attn_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ga3jimi6rwDy"
   },
   "outputs": [],
   "source": [
    "# ENCODER LAYER\n",
    "\n",
    "class SiglipEncoderLayer(nn.Module):\n",
    "    def __init__(self, config: SiglipVisionConfig):\n",
    "        super().__init__()\n",
    "        self.embed_dim = config.hidden_size\n",
    "        self.self_attn = SiglipAttention(config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_eps)\n",
    "        self.mlp = SiglipMLP(config)\n",
    "        self.layer_norm2 = nn.LayerNorm(self.embed_dim, eps=config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        # first residual block\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.layer_norm1(hidden_states)\n",
    "        hidden_states = self.self_attn(hidden_states)\n",
    "        hidden_states += residual\n",
    "\n",
    "        # second residual block\n",
    "        residual = hidden_states\n",
    "        hidden_states = self.layer_norm2(hidden_states)\n",
    "        hidden_states = self.mlp(hidden_states)\n",
    "        hidden_states += residual\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0iG9ohdvryHU"
   },
   "outputs": [],
   "source": [
    "# FULL ENCODER\n",
    "\n",
    "class SiglipEncoder(nn.Module):\n",
    "    def __init__(self, config: SiglipVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # stacking multiple encoder layers -\n",
    "        self.layers = nn.ModuleList([SiglipEncoderLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        for layer in self.layers:\n",
    "            hidden_states = layer(hidden_states)\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "cIZvafuJrd0E"
   },
   "outputs": [],
   "source": [
    "# complete VISION TRANSFORMER for CIFAR10 classification\n",
    "\n",
    "class CIFAR10VisionTransformer(nn.Module):\n",
    "    def __init__(self, config: SiglipVisionConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embeddings = SiglipVisionEmbeddings(config)\n",
    "        self.encoder = SiglipEncoder(config)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "\n",
    "        # classification head\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        hidden_states = self.embeddings(pixel_values)\n",
    "        hidden_states = self.encoder(hidden_states)\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "\n",
    "        # Use CLS token (first token) for classification\n",
    "        cls_token = hidden_states[:, 0]\n",
    "        logits = self.classifier(cls_token)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ROh_fBtMr2kP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "35f8e2c3-b68f-45e2-9426-256e99cf80f5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 170M/170M [00:03<00:00, 46.6MB/s]\n",
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 1/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:13<00:00,  5.31it/s, Loss=1.693, Acc=34.8%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1: Train Acc: 34.82%, Test Acc: 46.01%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 2/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.11it/s, Loss=1.284, Acc=45.5%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2: Train Acc: 45.51%, Test Acc: 53.47%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 3/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.12it/s, Loss=1.534, Acc=50.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3: Train Acc: 50.15%, Test Acc: 54.90%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 4/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=1.234, Acc=53.5%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4: Train Acc: 53.47%, Test Acc: 55.70%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 5/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=1.034, Acc=56.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5: Train Acc: 56.03%, Test Acc: 59.75%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 6/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=1.091, Acc=58.4%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6: Train Acc: 58.37%, Test Acc: 61.69%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 7/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.946, Acc=60.3%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7: Train Acc: 60.27%, Test Acc: 62.74%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 8/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=1.056, Acc=62.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8: Train Acc: 62.07%, Test Acc: 64.19%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 9/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.948, Acc=63.7%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9: Train Acc: 63.74%, Test Acc: 65.36%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 10/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.11it/s, Loss=1.034, Acc=65.3%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10: Train Acc: 65.30%, Test Acc: 67.13%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 11/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.935, Acc=67.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 11: Train Acc: 67.05%, Test Acc: 69.02%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 12/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.986, Acc=68.6%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 12: Train Acc: 68.60%, Test Acc: 69.77%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 13/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.766, Acc=69.5%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 13: Train Acc: 69.52%, Test Acc: 69.67%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 14/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.691, Acc=71.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 14: Train Acc: 70.97%, Test Acc: 71.99%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 15/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.807, Acc=72.2%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 15: Train Acc: 72.21%, Test Acc: 72.57%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 16/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.559, Acc=73.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 16: Train Acc: 73.04%, Test Acc: 73.45%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 17/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.966, Acc=74.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 17: Train Acc: 73.95%, Test Acc: 73.20%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 18/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.640, Acc=75.2%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 18: Train Acc: 75.25%, Test Acc: 74.46%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 19/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.633, Acc=76.3%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 19: Train Acc: 76.33%, Test Acc: 74.16%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 20/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.638, Acc=77.3%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 20: Train Acc: 77.29%, Test Acc: 75.63%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 21/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.639, Acc=78.3%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 21: Train Acc: 78.32%, Test Acc: 75.50%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 22/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.08it/s, Loss=0.459, Acc=79.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 22: Train Acc: 78.95%, Test Acc: 76.23%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 23/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.395, Acc=80.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 23: Train Acc: 80.10%, Test Acc: 76.37%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 24/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.08it/s, Loss=0.552, Acc=81.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 24: Train Acc: 81.06%, Test Acc: 76.32%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 25/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.328, Acc=81.8%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 25: Train Acc: 81.84%, Test Acc: 77.05%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 26/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.527, Acc=82.6%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 26: Train Acc: 82.65%, Test Acc: 77.64%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 27/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:17<00:00,  5.07it/s, Loss=0.684, Acc=83.8%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 27: Train Acc: 83.85%, Test Acc: 77.46%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 28/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.11it/s, Loss=0.362, Acc=84.6%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 28: Train Acc: 84.60%, Test Acc: 77.93%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 29/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.468, Acc=85.5%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 29: Train Acc: 85.52%, Test Acc: 78.45%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 30/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.08it/s, Loss=0.423, Acc=86.2%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 30: Train Acc: 86.21%, Test Acc: 78.28%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 31/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.396, Acc=87.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 31: Train Acc: 87.12%, Test Acc: 78.38%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 32/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.428, Acc=88.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 32: Train Acc: 88.01%, Test Acc: 78.64%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 33/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.300, Acc=89.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 33: Train Acc: 88.98%, Test Acc: 78.31%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 34/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.259, Acc=89.4%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 34: Train Acc: 89.43%, Test Acc: 78.66%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 35/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:17<00:00,  5.08it/s, Loss=0.247, Acc=90.2%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 35: Train Acc: 90.19%, Test Acc: 78.56%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 36/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.301, Acc=90.8%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 36: Train Acc: 90.78%, Test Acc: 78.32%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 37/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.259, Acc=91.5%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 37: Train Acc: 91.45%, Test Acc: 78.75%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 38/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.170, Acc=91.7%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 38: Train Acc: 91.67%, Test Acc: 78.79%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 39/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.270, Acc=92.5%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 39: Train Acc: 92.52%, Test Acc: 78.92%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 40/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.151, Acc=92.9%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 40: Train Acc: 92.87%, Test Acc: 79.26%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 41/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.256, Acc=93.1%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 41: Train Acc: 93.13%, Test Acc: 79.23%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 42/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.090, Acc=93.7%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 42: Train Acc: 93.69%, Test Acc: 78.74%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 43/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.08it/s, Loss=0.038, Acc=93.9%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 43: Train Acc: 93.93%, Test Acc: 78.98%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 44/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.233, Acc=94.2%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 44: Train Acc: 94.23%, Test Acc: 78.93%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 45/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.223, Acc=94.4%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 45: Train Acc: 94.45%, Test Acc: 79.15%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 46/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.133, Acc=94.6%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 46: Train Acc: 94.60%, Test Acc: 79.12%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 47/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.165, Acc=94.6%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 47: Train Acc: 94.61%, Test Acc: 79.23%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 48/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:17<00:00,  5.07it/s, Loss=0.180, Acc=94.6%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 48: Train Acc: 94.61%, Test Acc: 79.26%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 49/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.09it/s, Loss=0.235, Acc=95.0%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 49: Train Acc: 95.03%, Test Acc: 79.30%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 50/50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 391/391 [01:16<00:00,  5.10it/s, Loss=0.106, Acc=94.8%]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 50: Train Acc: 94.84%, Test Acc: 79.28%\n",
      "Best Test Accuracy: 79.30%\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADING AND TRAINING\n\ndef main():\n    # loading CIFAR10 dataset\n    train_transform, test_transform = get_cifar10_transforms()\n\n    trainset = torchvision.datasets.CIFAR10(\n        root='./data',\n        train=True,\n        download=True,\n        transform=train_transform\n    )\n    testset = torchvision.datasets.CIFAR10(\n        root='./data',\n        train=False,\n        download=True,\n        transform=test_transform\n    )\n\n    trainloader = DataLoader(trainset, bs=128, shuffle=True, num_workers=4, pin_memory=True)\n    testloader = DataLoader(testset, bs=128, shuffle=False, num_workers=4, pin_memory=True)\n\n    # CIFAR10 classes names\n    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\n    # Model, loss, opt\n    config = SiglipVisionConfig()\n    vit_model = CIFAR10VisionTransformer(config).cuda()\n    loss_fn = nn.CrossEntropyLoss() # loss function\n    opt = optim.AdamW(vit_model.parameters(), learning_rate=3e-4, weight_decay=0.05)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(opt, T_max=50)\n\n\n\n    # Training loop\n    num_epochs = 50\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        # Training\n        vit_model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n\n        pbar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n        for batch_idx, (inputs, targets) in enumerate(pbar):\n            inputs, targets = inputs.cuda(), targets.cuda()\n\n            opt.zero_grad()\n            outputs = vit_model(inputs)\n            loss = loss_fn(outputs, targets)\n            loss.backward()\n\n            # gradient clipping\n            torch.nn.utils.clip_grad_norm_(vit_model.parameters(), max_norm=1.0)\n            opt.step()\n\n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_total += targets.size(0)\n            train_correct += predicted.eq(targets).sum().item()\n\n            pbar.set_postfix({\n                'Loss': f'{loss.item():.3f}',\n                'Acc': f'{100.*train_correct/train_total:.1f}%'\n            })\n\n        scheduler.step()\n\n\n\n\n        # Evaluation\n        vit_model.eval()\n        test_loss = 0.0\n        test_correct = 0\n        test_total = 0\n\n        with torch.no_grad():\n            for inputs, targets in testloader:\n                inputs, targets = inputs.cuda(), targets.cuda()\n                outputs = vit_model(inputs)\n                loss = loss_fn(outputs, targets)\n\n                test_loss += loss.item()\n                _, predicted = outputs.max(1)\n                test_total += targets.size(0)\n                test_correct += predicted.eq(targets).sum().item()\n\n        train_acc = 100. * train_correct / train_total\n        test_acc = 100. * test_correct / test_total\n\n\n        print(f'Epoch {epoch+1}: Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%')\n\n\n\n\n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(vit_model.state_dict(), 'best_cifar10_vit.pth')\n\n    print(f'Best Test Accuracy: {best_acc:.2f}%')\n\nif __name__ == \"__main__\":\n    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Vision Transformer implemented from scratch was successfully trained on the CIFAR-10 dataset.\n",
    "\n",
    "The model achieved a ***Training accuracy*** of ***~95%*** and a ***Best Test accuracy*** of ***~79%***.\n",
    "\n",
    "This indicates that the model exhibits a noticeable gap between training and testing performance. This behavior is expected for models trained on small datasets such as CIFAR-10.\n",
    "\n"
   ],
   "metadata": {
    "id": "7Vb3GKYUHwx5"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}